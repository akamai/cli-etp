#!/usr/bin/env python3

# Copyright 2023 Akamai Technologies, Inc. All Rights Reserved
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Standard modules

import sys
import os
import json
import json.decoder
import ipaddress
import time
import signal
from threading import Event
from enum import Enum
import logging
from urllib.parse import parse_qs
import csv
import math
from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED
from datetime import timedelta

# 3rd party modules

import requests
from requests.adapters import HTTPAdapter, Retry
from requests.compat import urljoin
from akamai.edgegrid import EdgeGridAuth, EdgeRc
from config import EdgeGridConfig

__version__ = "0.4.5"

#: Window span in ad-hoc mode, default is 3 min
span_duration_min = 3

session = None
verbose = False
section_name = "default"
headers = {'Accept': "application/json"}
extra_qs = None

LOG = logging.getLogger("cli-etp")
LOG_FMT = '%(asctime)s %(name)s %(threadName)s %(levelname).1s %(message)s'
EVENT_PAGE_SIZE = 5000
MAX_FETCH_CONCURRENCY = 8

# If all parameters are set already, use them.  Otherwise
# use the config
config = EdgeGridConfig({"verbose": False}, section_name)

#: Verbose mode, configurable with -v or --verbose
verbose = getattr(config, "verbose", False)
#: Fetch limit in seconds, configurable with --limit, default is 3 minutes
fetch_limit = getattr(config, "limit", 3 * 60)
#: Poll interval (also defines how much data we get each time)
#: Default is 1 minute, configurable with --poll
poll_interval_sec = getattr(config, "poll", 60)

baseurl = '%s://%s' % ('https', getattr(config, "host", "host-not-set-in-config"))
stop_event = Event()


class ETPListType(Enum):
    """See https://developer.akamai.com/api/enterprise_security/enterprise_threat_protector_configuration/v1.html"""
    IP = "LIST_TYPE_IP"
    DOMAIN = "LIST_TYPE_DOMAIN"


class ETPConfidence(Enum):
    SUSPECTED = 1
    KNOWN = 2


class ETPListCategory(Enum):
    MALWARE = 1
    PHISHING = 2
    CNC = 3
    OTHER = 4


class ETPEventFetchStats(object):

    # General stats for the whole cli process lifetime
    bytes = 0           #: Response payload length in bytes
    events = 0          #: Number total of events fetched
    api_calls = 0       #: Total Number of API called issued
    api_calls_fail = 0  #: Total Number of API called failed

    # Stats by poll interval
    poll_cycles = 0     #: When using --tail mode, how many cycles we went through
    poll_events = 0     #: Number of events fetched during the current poll interval (tail mode)
    poll_api_calls = 0  #: Total Number of API called issued during the current poll
    #: Timedelta spent in network operation (Request/Response) for the poll interval
    poll_elapsed = timedelta()

    def inc_event(self):
        "Increment the number of event by 1."
        self.events += 1
        self.poll_events += 1

    def inc_api_call(self):
        self.api_calls += 1
        self.poll_api_calls += 1

    def inc_poll_cycle(self):
        "Mark a new pool cycle."
        self.poll_events = 0
        self.poll_api_calls = 0
        self.poll_cycles += 1
        self.poll_elapsed = timedelta()

    def inc_poll_elapsed(self, d: timedelta):
        self.poll_elapsed += d


def exit_fromresponse(response):
    """
    Convert an HTTP Code into an CLI return code.
    """
    if response is None:
        exit(1)
    if response.status_code == 200:
        exit(0)
    else:
        reason = None
        try:
            reason = response.json().get("detail")
        except ValueError:
            pass
        sys.stderr.write("ERROR: Exiting with code %s, reason: %s, use -d or -v for more details.\n" % (response.status_code, reason))
        if response.status_code == 401:
            LOG.error(f"ERROR: Client Token was: {config.client_token} in [{config.section}]")
        exit(response.status_code)


def type_hostorip(hostorip):
    """
    Detect if a string is an actual IP address (IPv4 or IPv6) or an hostname
    """
    if not isinstance(hostorip, str):
        raise ValueError('hostorip must be a unicode string, %s provided' %
                         type(hostorip).__name__)
    try:
        ipaddress.ip_address(hostorip)
        return ETPListType.IP
    except ValueError:
        return ETPListType.DOMAIN


def iphost_argument_tolist(config):
    for item in config.iporhost:
        if item[0:1] == "@":
            filename = item[1:]
            if filename == "-":
                for line in sys.stdin:
                    yield line.strip()
            else:
                with open(filename, "r") as f:
                    for line in f:
                        yield line.strip()
        else:
            yield item


def build_params(params=None):
    """
    Prepare querystring arguments as key value pair

    Args:
        params (dict, optional): Querystring Arguments as key-value dict. Defaults to None.

    Returns:
        dict: Fully constructed KV dict
    """
    if isinstance(params, dict):
        final_params = params.copy()
    else:
        final_params = {}
    edgerc = EdgeRc(config.edgerc)
    scanned_extra_qs = edgerc.get(config.section, 'extra_qs', fallback=None)
    if scanned_extra_qs:
        final_params.update(parse_qs(scanned_extra_qs))
    return final_params


class cli:
    """
    Various shared functions for CLI
    """
    @staticmethod
    def write(s):
        print(s)

    @staticmethod
    def write_header(s):
        sys.stderr.write(s)
        sys.stderr.write("\n")

    @staticmethod
    def write_footer(s):
        cli.write_header(s)

    @staticmethod
    def write_columns(row):
        writer = csv.writer(sys.stdout)
        writer.writerow(row)

    @staticmethod
    def current_command():
        return "akamai etp " + " ".join(sys.argv[1:])


def input2feed(event_type):
    api_eventtype = None
    if event_type == "threat":
        api_eventtype = "threat-events"
    elif event_type == "aup":
        api_eventtype = "aup-events"
    elif event_type == "dns":
        api_eventtype = "dns-activities"
    elif event_type == "proxy":
        api_eventtype = "proxy-traffic/transactions"
    elif event_type == "netcon":
        api_eventtype = "network-traffic/connections"
    if api_eventtype is None:
        raise ValueError(f'event_type provided is support supported: {event_type}')
    return api_eventtype


def exit_gracefully(signum, frame):
    """
    Operation to stop the CLI as quickly and cleanly as possible
    Handler to pass to the signal.signal().
    """
    global stop_event
    stop_event.set()


def fetch_event_page(start, end, page_number, thread_pool, pool_futures, stats, output):
    """
    Fetch a single page of result from ETP API
    It runs the API call and write the output
    First page (page_number == 1):
      We look into the response
      and if additional pages need to be queried,
      we submit more fetch_event_page() into
      the ThreadPoolExecutor
    Every case, it writes the output
    """
    if stop_event.is_set():
        LOG.debug(f"Fetch page #{page_number} aborted (reason: stop_event is set)")
        return

    post_data = {
        'startTimeSec': start,
        'endTimeSec': end,
        'orderBy': "ASC",
        'pageNumber': page_number,
        'pageSize': EVENT_PAGE_SIZE,
        'filters': {}
    }
    event_url = '%(baseurl)s/etp-report/v3/configs/%(config_id)s/%(event_type)s/details' % \
        {
            'baseurl': baseurl,
            'config_id': config.etp_config_id,
            'event_type': input2feed(config.event_type)
        }
    LOG.info("{OPEN} API URL: %s" % event_url)
    LOG.info("{OPEN} API POST param %s" % post_data)
    try:
        r = session.post(event_url, params=build_params(),
                         json=post_data, headers=headers, timeout=min(300, poll_interval_sec*2))
        stats.inc_api_call()
        LOG.info(f"{{OPEN}} API response code is HTTP/{r.status_code}, body {len(r.content):,} "
                 f"bytes, page #{page_number}")
        if r.status_code != 200:
            stats.api_calls_fail += 1
            LOG.error(f"API call failed with HTTP/{r.status_code}: {r.content}")

        stats.inc_poll_elapsed(r.elapsed)
        LOG.info("{OPEN} API call took %.2f seconds, page #%s" % (r.elapsed.total_seconds(), page_number))
        response_data = r.json()
        stats.bytes += len(r.content)

        for e in response_data.get('dataRows', []):
            output.write("%s\n" % json.dumps(e))
            stats.inc_event()
        output.flush()

        if page_number == 1:
            LOG.info("Page info: %s" % response_data.get("pageInfo", {}))
            total_records = response_data["pageInfo"]["totalRecords"]
            numOfPages = int((total_records / EVENT_PAGE_SIZE) + 1)
            if numOfPages > 1:
                LOG.info(f"Calculated number of pages: {numOfPages} (based on {total_records:,} total events)")
                for p in range(2, numOfPages+1):
                    LOG.debug(f"Adding a new fetch call for page {p}...")
                    try:
                        pool_futures.append(thread_pool.submit(
                            fetch_event_page, start, end, p, thread_pool, pool_futures, stats, output))
                    except Exception:
                        LOG.exception("Uh oh")

    except requests.exceptions.ReadTimeout:
        LOG.warning("Request timeout")


def events_summary(start, end, config):
    """
    Fetch the summary of a particular timeframe of events.
    API ref:
        https://techdocs.akamai.com/etp-reporting/reference/get-dns-activities
    """
    api_url = '%(baseurl)s/etp-report/v3/configs/%(config_id)s/%(event_type)s/aggregate' % \
        {
            'baseurl': baseurl,
            'config_id': config.etp_config_id,
            'event_type': input2feed(config.event_type)
        }
    try:
        LOG.info(api_url)
        r = session.get(api_url, params=build_params({"startTimeSec": start, "endTimeSec": end}))
        LOG.debug(f"Aggregate report: {r.text} events")
        data = r.json()
        total = 0
        if len(data.get("aggregations", [])) > 0:
            total = data.get("aggregations", [])[0].get("total")
        return total
    except Exception:
        LOG.exception(f"Error fetching {config.event_type} summary...")


def fetch_events_concurrent(config, output):
    """
    Fetch ETP security events
    Unlike the old fetch_events (prior to cli-etp 0.4.1) this version is optimized
    to fetch the pages with concurrency leveraging a pool of thread.
    """
    stats = ETPEventFetchStats()

    if config.tail:  # The window span is set we can keep adding content by small increment
        start = int(time.time()) - fetch_limit - poll_interval_sec
        end = start + poll_interval_sec
        signal.signal(signal.SIGTERM, exit_gracefully)
        signal.signal(signal.SIGINT, exit_gracefully)
    else:  # Larger window span
        start = int(time.time()) - fetch_limit - (span_duration_min * 60)
        if config.start:
            start = config.start
        end = start + (span_duration_min * 60)
        if config.end:
            end = config.end

    pool_futures = []
    concurrent_fetch = ThreadPoolExecutor(
        max_workers=min(config.concurrent, MAX_FETCH_CONCURRENCY),
        thread_name_prefix="ApiFetch")

    while not stop_event.is_set():
        timing_s = time.time()
        expected_event_count = events_summary(start, end, config)
        # 1st page fetch is executed in the main cli thread, optional subsequent
        # ones are executed within the thread pool
        fetch_event_page(start, end, 1, concurrent_fetch, pool_futures, stats, output)
        # Wait until all the API calls fetching pages are processed
        try:
            wait(pool_futures, return_when=ALL_COMPLETED)
            if not config.tail:
                break
            else:
                LOG.info(f"[tail] Fetched {stats.poll_events:,} event(s), "
                         f"{expected_event_count:,} expected, "
                         f"{stats.poll_api_calls} API calls, "
                         f"{stats.poll_elapsed} elapsed for this cycle")
                stats.inc_poll_cycle()  # Reset the per cycle counters
                LOG.info(f"[tail] Fetched {stats.events:,} event(s), ran {stats.poll_cycles} cycle(s)")
                if stop_event.is_set():
                    break
                # Here we assume the fetch elapsed time should take less than poll_interval_sec
                # otherwise we may have datagaps
                sleep_time = max(0, poll_interval_sec - (time.time() - timing_s))
                if sleep_time == 0:
                    LOG.warning(f"Slow incoming data, consider shorter --poll interval (currently {poll_interval_sec})"
                                f" or --concurrent (currently {config.concurrent})")
                LOG.info("Sleeping for %.2f sec..." % sleep_time)
                if not stop_event.wait(sleep_time):
                    start = end  # next cycle resume where we finish this one
                    end = int(time.time()) - fetch_limit  # the window ends at now - limit
                    LOG.info(f"Next cycle will be from {start} to {end} [{end - start}s]...")
        except KeyboardInterrupt:
            LOG.warning("Keyboard interrupt detected, abort")
            stop_event.set()
        except requests.exceptions.ReadTimeout:
            LOG.warning(f"Request timeout, consider increase poll interval (currently {poll_interval_sec}s)")
        finally:
            LOG.info(f"{stats.events:,} event(s) fetched in total, {expected_event_count:,} expected, "
                     f"{stats.bytes:,} byte(s), "
                     f"{stats.api_calls} API calls")


def list_create(config):
    """
    Create a new custom security list
    API ref: https://techdocs.akamai.com/etp-config/reference/post-list
    """
    payload = {
        "name": config.name,
        "description": config.description,
        "securityCategoryId": config.category
    }
    create_list_api = urljoin(baseurl, f"/etp-config/v3/configs/{config.etp_config_id}/lists")
    r = session.post(create_list_api, params=build_params(), json=payload)
    newlisturl = r.headers.get('Location')
    if r.status_code == 200 and newlisturl:
        cli.write("Security list {} created.".format(newlisturl[newlisturl.rfind('/')+1:]))
    exit_fromresponse(r)


def list_delete(config):
    """
    Delete a custom security list
    API ref: NOT DOCUMENTED as of 2022-11-14
             Simply call the DELETE method with If-Match as documented here
             https://techdocs.akamai.com/etp-config/reference/object-versioning
    """
    delete_list_api = urljoin(baseurl, f"/etp-config/v3/configs/{config.etp_config_id}/lists/{config.listid}")
    read = session.get(delete_list_api, params=build_params(), headers=headers)
    etag = read.headers.get('ETag')
    delete_headers = headers.copy()
    delete_headers['If-Match'] = etag
    r = session.delete(delete_list_api, params=build_params(), headers=delete_headers)
    if r.status_code == 200:
        cli.write(f"Security List {config.listid} deleted.")
    exit_fromresponse(r)


def list_add_or_delete_item(config):
    # Maps security command line argument with dict key
    action_key = "add"
    if config.list_action == "remove_item":
        action_key = "delete"
    confidence = ETPConfidence.KNOWN
    if action_key == "add" and config.suspect:
        confidence = ETPConfidence.SUSPECTED

    LOG.info("%s %s to the list %s (confidence: %s)" %
             (action_key, config.iporhost, config.listid, confidence))

    add_item_url = urljoin(baseurl, "/etp-config/v1/configs/%s/lists/%s/items" %
                           (config.etp_config_id, config.listid))

    LOG.info("Webservice URL: %s" % add_item_url)

    change = {
        "add": [],
        "delete": []
        }
    for item in iphost_argument_tolist(config):
        if action_key == "add":
            change[action_key].append({
                "type": type_hostorip(item).value,
                "value": item,
                "confidenceLevelId": confidence.value
            })
        else:
            change[action_key].append(item)
    if verbose:
        print("== payload ===")
        print(json.dumps(change))

    r = session.patch(add_item_url,  params=build_params(), json=change, headers=headers)
    exit_fromresponse(r)


class ioc:

    recordType = 'DOMAIN'

    @staticmethod
    def isrisky(domain):
        params = {'record': domain, 'recordType': ioc.recordType}
        path = '/etp-report/v1/ioc/domain-tree'
        resp = session.get(urljoin(baseurl, path), params=build_params(params))
        LOG.info("API: %s returns HTTP/%s" % (path, resp.status_code))
        domaintree = resp.json()
        return len(domaintree) > 0

    @staticmethod
    def info(domain):
        """IOC information about the domain."""
        params = {'record': domain, 'recordType': ioc.recordType}
        path = '/etp-report/v1/ioc/information'
        resp = session.get(urljoin(baseurl, path), params=build_params(params))
        LOG.info("API: %s returns HTTP/%s" % (path, resp.status_code))
        print(resp.text)

    @staticmethod
    def timeseries(domain):
        """IOC time series about the domain."""
        params = {'record': domain, 'recordType': ioc.recordType}
        path = "/etp-report/v1/configs/100/ioc/time-series"
        resp = session.get(urljoin(baseurl, path), params=build_params(params))
        LOG.info("API: %s returns HTTP/%s" % (path, resp.status_code))
        data = resp.json()
        if len(data.get('rows', [])) > 0:
            print(resp.text)
        else:
            sys.stderr.write("Domain not seen before.\n")
            sys.exit(3)

    @staticmethod
    def changes(domain):
        """IOC observed changes on a domain."""
        params = {'record': domain, 'recordType': ioc.recordType}
        path = '/etp-report/v1/ioc/changes'
        resp = session.get(urljoin(baseurl, path), params=build_params(params))
        LOG.info("API: %s returns HTTP/%s" % (path, resp.status_code))
        print(resp.text)


class report:

    @staticmethod
    def active_clients(start, end, configId=None):
        path = '/etp-config/v3/configs/{configId}/client/status'.format(
            configId=configId or config.etp_config_id)
        params = {'startTimeSec': start, 'endTimeSec': end}
        resp = session.get(urljoin(baseurl, path), params=build_params(params))
        grand_total = 0
        for operating_system in resp.json().get('installed', []):
            grand_total += operating_system.get('total', 0)
        return grand_total


class tenant:
    """
    Operate on sub-tenants, ETP feature introduce late 2021.
    """
    @staticmethod
    def _get_all():
        path = '/etp-config/v3/configs/{configId}/tenants'.format(
            configId=config.etp_config_id)
        resp = session.get(urljoin(baseurl, path), params=build_params())
        if resp.status_code != 200:
            sys.stderr.write(f"Error fetching tenants:\n{resp.text}\n")
            sys.exit(2)
        return resp.json()

    @staticmethod
    def list():
        tenants = tenant._get_all()
        cli.write_header('# Command: {0}'.format(cli.current_command()))
        cli.write_header("# ConfigID, name")
        for t in tenants:
            cli.write_columns((t.get("id"), t.get("name")))

    @staticmethod
    def report_active_clients():

        tenants = tenant._get_all()

        # Date/time boundaries
        end = config.end or int(time.time())
        start = config.start or (end - (30 * 24 * 60 * 60))

        # CSV Headers
        cli.write_header('# Command: {0}'.format(cli.current_command()))
        cli.write_header(f'# Report start: {start}')
        cli.write_header(f'# Report end: {end}')
        cli.write_header("# config_id, tenant_name, active_client_count")

        for t in tenants:
            cli.write_columns((t.get('id'),  t.get('name'), report.active_clients(start, end, t.get('id'))))


def log_level():
    if config.debug:
        return logging.DEBUG
    elif config.verbose:
        return logging.INFO
    else:
        return logging.ERROR


def prepare_session(config):
    """
    Prepare a Session object to issue request against Akamai {OPEN} API
    """
    s = requests.Session()

    # Initialize Requests Session for the API calls
    s.auth = EdgeGridAuth(
        client_token=config.client_token,
        client_secret=config.client_secret,
        access_token=config.access_token
    )

    # Proxy
    if config.proxy:
        LOG.info("Set proxy to %s" % config.proxy)
        s.proxies['https'] = 'http://%s' % config.proxy

    # Retry
    retry_policy = Retry(total=5, backoff_factor=1, allowed_methods=["GET", "POST"],
                         status_forcelist=[429, 500, 502, 503, 504])
    retry_adapter = HTTPAdapter(max_retries=retry_policy)
    s.mount("https://", retry_adapter)

    # User agent, with an optional prefix
    s.headers.update({'User-Agent': f"{config.ua_prefix} cli-etp/{__version__}"})

    return s


def setup_logging():
    """
    Allow the CLI to format the log the same way either in debug or verbose mode.
    Starting python 3.8, we could use logging.basicConfig() with force=True although
    we are still supporing Python 3.6 at this point.
    """
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    logging.basicConfig(
        filename=config.logfile, level=log_level(), format=LOG_FMT
    )


def main():

    global session

    setup_logging()

    LOG.info("Python %s" % ' '.join(sys.version.splitlines()))
    LOG.info(f"cli-etp version {__version__}, PID: {os.getpid()}")
    LOG.info("Command is: %s" % config.command)
    LOG.info("ETP Config ID: %s" % getattr(config, 'etp_config_id', None))
    LOG.info(f"Tail fetch limit: {fetch_limit} seconds")
    LOG.info(f"Tail poll interval: {poll_interval_sec} seconds")

    if not config.command:
        config.parser.print_help()
        sys.exit(0)
    elif config.command == "version":
        print(__version__)
        sys.exit(0)

    session = prepare_session(config)

    if config.command == "event":
        if config.output is None:
            out = sys.stdout
        else:
            LOG.info("Output file: %s" % config.output)
            out = open(config.output, 'w+')
        try:
            fetch_events_concurrent(config, out)
        finally:
            if out is not None and out != sys.stdout:
                LOG.info("Closing output file %s..." % config.output)
                out.close()

    elif config.command == "list":
        if config.list_action == "create":
            list_create(config)
        elif config.list_action == "delete":
            list_delete(config)
        elif config.list_action in ("add_item", "remove_item"):
            list_add_or_delete_item(config)
        elif config.list_action == "deploy":
            url = urljoin(baseurl, "/etp-config/v1/configs/%s/lists/deployments" % config.etp_config_id)
            payload = {
                "id": config.listid,
                "status": "PENDING"
            }
            r = session.post(url, params=build_params(), data=json.dumps(payload), headers=headers)
            exit_fromresponse(r)
        elif config.list_action == "get":
            if config.listid:
                # https://techdocs.akamai.com/etp-config/reference/get-list
                url = urljoin(baseurl, "/etp-config/v3/configs/{configId}/lists/{listId}/items".format(
                    configId=config.etp_config_id,
                    listId=config.listid
                ))
                page_number = 0
                page_size = 50
                total_page = None
                while total_page is None or page_number < total_page:
                    r = session.get(url, params=build_params({'page': page_number, 'numItemsPerPage': page_size}),
                                    headers=headers)
                    if r.status_code == 200:
                        data = r.json()
                        page_number += 1
                        total_page = math.ceil(data.get('totalCount') / page_size)
                        for dom in r.json().get("items", []):
                            cli.write(dom.get('value'))
                exit_fromresponse(r)
            else:
                url = urljoin(baseurl, "/etp-config/v1/configs/%s/lists" % (config.etp_config_id))
                r = session.get(url, params=build_params(), headers=headers)
                if r.status_code == 200:
                    for list_item in r.json():
                        print("%s,%s" % (list_item.get("id"), list_item.get('name')))
                exit_fromresponse(r)
        else:
            sys.stderr.write("Action %s not implemented.\n" % config.list_action)
    elif config.command == "ioc":
        if not config.domain or not ioc.isrisky(config.domain):
            sys.exit(2)
        if config.ioc_action == "info":
            ioc.info(config.domain)
        if config.ioc_action == "timeseries":
            ioc.timeseries(config.domain)
        elif config.ioc_action == "changes":
            ioc.changes(config.domain)
    elif config.command == "tenant":
        if config.operation == "list":
            tenant.list()
        elif config.operation == "clients":
            tenant.report_active_clients()
        else:
            print("Not supported")


if __name__ == '__main__':
    main()
